@online{li_fei_fei,
    author = "Li Fei-Fei",
    title = "With spatial intelligence, AI will understand the real world",
    url  = "https://www.ted.com/talks/fei_fei_li_with_spatial_intelligence_ai_will_understand_the_real_world",
    keywords = "li fei-fei, ted talk, spatial intelligence, ai, real world"
}

@article{lecun_cnn,
    author = "Yan LeCun",
    title = "Backpropagation applied to handwritten zip code recognition",
    journal = "Neural Computation",
    volume = "1",
    pages = "541--551",
    year = "1989",
    DOI = "10.1162/neco.1989.1.4.541",
    keywords = "CNN"
}

@article{alexnet,
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    title = {ImageNet classification with deep convolutional neural networks},
    year = {2012},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
    booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
    pages = {1097â€“1105},
    numpages = {9},
    location = {Lake Tahoe, Nevada},
    series = {NIPS'12}
}

@article{vgg,
  author       = "Karen Simonyan and Andrew Zisserman",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}

@article{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{lenet,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}

@article{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@online{human_visual_cortex,
  author={Zoumana Keita},
  title={An Introduction to Convolutional Neural Networks (CNNs)},
  url={https://www.datacamp.com/tutorial/introduction-to-convolutional-neural-networks-cnns},
  keywords={CNN, human visual cortex}
}
